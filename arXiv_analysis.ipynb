{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'setup.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "# Create your connection.\n",
    "cnx = sqlite3.connect('test.db')\n",
    "#load database to Pandas Data frame 'df'\n",
    "df = pd.read_sql_query(\"SELECT * FROM arxiv_cs_publications\", cnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Database Schema\n",
    "#+---------------------+       \n",
    "#|arxiv_cs_publications|       \n",
    "#-----------------------       \n",
    "#|publication_id(pk)   |       \n",
    "#|title                |       \n",
    "#|description          |       \n",
    "#|subject              |       \n",
    "#|version              |       \n",
    "#|created_date         |       \n",
    "#+---------------------+\n",
    "\n",
    "#Article Link = \"https://arxiv.org/abs/\" + version\n",
    "#Article PDF  = \"https://arxiv.org/pdf/\" + version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entry_id               275\n",
       "title                  275\n",
       "description            275\n",
       "subject                275\n",
       "publication_id         275\n",
       "publication_version    275\n",
       "created_date           275\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 275 entries, 0 to 274\n",
      "Data columns (total 7 columns):\n",
      "entry_id               275 non-null int64\n",
      "title                  275 non-null object\n",
      "description            275 non-null object\n",
      "subject                275 non-null object\n",
      "publication_id         275 non-null object\n",
      "publication_version    275 non-null object\n",
      "created_date           275 non-null object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 15.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>subject</th>\n",
       "      <th>publication_id</th>\n",
       "      <th>publication_version</th>\n",
       "      <th>created_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Efficient Estimation of Heat Kernel PageRank f...</td>\n",
       "      <td>Given an undirected graph G and a seed node s,...</td>\n",
       "      <td>cs.SI</td>\n",
       "      <td>1904.02707</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-08 18:43:47.575287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bounties in Open Source Development on GitHub:...</td>\n",
       "      <td>Due to the voluntary nature of open source sof...</td>\n",
       "      <td>cs.SE</td>\n",
       "      <td>1904.02724</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-08 18:43:47.601873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Towards Specifying Symbolic Computation.</td>\n",
       "      <td>Many interesting and useful symbolic computati...</td>\n",
       "      <td>cs.LO</td>\n",
       "      <td>1904.02729</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-08 18:43:47.621823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Neural Models of the Psychosemantics of `Most'.</td>\n",
       "      <td>How are the meanings of linguistic expressions...</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>1904.02734</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-08 18:43:47.652527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>On Topological and Metrical Properties of Stab...</td>\n",
       "      <td>In this paper, we discuss various topological ...</td>\n",
       "      <td>cs.SY</td>\n",
       "      <td>1904.02737</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-08 18:43:47.670984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   entry_id                                              title  \\\n",
       "0         1  Efficient Estimation of Heat Kernel PageRank f...   \n",
       "1         2  Bounties in Open Source Development on GitHub:...   \n",
       "2         3          Towards Specifying Symbolic Computation.    \n",
       "3         4   Neural Models of the Psychosemantics of `Most'.    \n",
       "4         5  On Topological and Metrical Properties of Stab...   \n",
       "\n",
       "                                         description subject publication_id  \\\n",
       "0  Given an undirected graph G and a seed node s,...   cs.SI     1904.02707   \n",
       "1  Due to the voluntary nature of open source sof...   cs.SE     1904.02724   \n",
       "2  Many interesting and useful symbolic computati...   cs.LO     1904.02729   \n",
       "3  How are the meanings of linguistic expressions...   cs.CL     1904.02734   \n",
       "4  In this paper, we discuss various topological ...   cs.SY     1904.02737   \n",
       "\n",
       "  publication_version                created_date  \n",
       "0                  1   2019-04-08 18:43:47.575287  \n",
       "1                  1   2019-04-08 18:43:47.601873  \n",
       "2                  1   2019-04-08 18:43:47.621823  \n",
       "3                  1   2019-04-08 18:43:47.652527  \n",
       "4                  1   2019-04-08 18:43:47.670984  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for duplicate versions of a publication\n",
    "df_checkV = pd.read_sql_query(\"\"\"SELECT count (publication_id),publication_id,title, publication_version\n",
    "                              FROM arxiv_cs_publications\n",
    "                              group by publication_id\n",
    "                              having count (publication_id)\t > 1\"\"\", cnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count (publication_id)</th>\n",
       "      <th>publication_id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication_version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [count (publication_id), publication_id, title, publication_version]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_checkV.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count the number of words in each publication description \n",
    "df['total_words'] = df['description'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>total_words</th>\n",
       "      <th>words_minus_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Given an undirected graph G and a seed node s,...</td>\n",
       "      <td>83</td>\n",
       "      <td>239</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Due to the voluntary nature of open source sof...</td>\n",
       "      <td>108</td>\n",
       "      <td>249</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Many interesting and useful symbolic computati...</td>\n",
       "      <td>27</td>\n",
       "      <td>70</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How are the meanings of linguistic expressions...</td>\n",
       "      <td>48</td>\n",
       "      <td>146</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In this paper, we discuss various topological ...</td>\n",
       "      <td>34</td>\n",
       "      <td>91</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  stopwords  total_words  \\\n",
       "0  Given an undirected graph G and a seed node s,...         83          239   \n",
       "1  Due to the voluntary nature of open source sof...        108          249   \n",
       "2  Many interesting and useful symbolic computati...         27           70   \n",
       "3  How are the meanings of linguistic expressions...         48          146   \n",
       "4  In this paper, we discuss various topological ...         34           91   \n",
       "\n",
       "   words_minus_stopwords  \n",
       "0                    156  \n",
       "1                    141  \n",
       "2                     43  \n",
       "3                     98  \n",
       "4                     57  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the number of stop words per description \n",
    "#In natural language processing, useless words (data), are referred to as stop words. \n",
    "#Stop Words: A stop word is a commonly used word (such as “the”, “a”, “an”, “in”)\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "df['stopwords'] = df['description'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "\n",
    "df['words_minus_stopwords'] = df[\"total_words\"] - df[\"stopwords\"]\n",
    "\n",
    "df[['description','stopwords','total_words','words_minus_stopwords']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    mobile robots that manipulate their environmen...\n",
       "1    multi-task learning, as it is understood nowad...\n",
       "2    well established libraries typically have api ...\n",
       "3    an equiangular tight frame (etf) is a sequence...\n",
       "4    we present a coarse-to-fine approach based sem...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All words to lower case\n",
    "df['description'] = df['description'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "df['description'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    mobile robots that manipulate their environmen...\n",
       "1    multitask learning as it is understood nowaday...\n",
       "2    well established libraries typically have api ...\n",
       "3    an equiangular tight frame etf is a sequence o...\n",
       "4    we present a coarsetofine approach based semia...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove punctuation\n",
    "df['description'] = df['description'].str.replace('[^\\w\\s]','')\n",
    "df['description'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    mobile robots manipulate environments require ...\n",
       "1    multitask learning understood nowadays consist...\n",
       "2    well established libraries typically api docum...\n",
       "3    equiangular tight frame etf sequence unitnorm ...\n",
       "4    present coarsetofine approach based semiautono...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove Stop words\n",
    "df['description'] = df['description'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "df['description'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data           176\n",
      "learning       160\n",
      "model          144\n",
      "paper          128\n",
      "performance    125\n",
      "proposed       112\n",
      "using          110\n",
      "show           107\n",
      "network        106\n",
      "problem        102\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    mobile robots manipulate environments require ...\n",
       "1    multitask understood nowadays consists one sin...\n",
       "2    well established libraries typically api docum...\n",
       "3    equiangular tight frame etf sequence unitnorm ...\n",
       "4    present coarsetofine approach based semiautono...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top Ten most Frequent Words\n",
    "freq = pd.Series(' '.join(df['description']).split()).value_counts()[:10]\n",
    "print(freq)\n",
    "#Remove top ten most frequent words\n",
    "freq = list(freq.index)\n",
    "df['description'] = df['description'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "df['description'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [mobile, robots, manipulate, environments, req...\n",
       "1      [multitask, understood, nowadays, consists, on...\n",
       "2      [well, established, libraries, typically, api,...\n",
       "3      [equiangular, tight, frame, etf, sequence, uni...\n",
       "4      [present, coarsetofine, approach, based, semia...\n",
       "5      [image, understanding, relies, heavily, accura...\n",
       "6      [consuming, news, social, media, becoming, inc...\n",
       "7      [new, deep, based, dense, monocular, slam, met...\n",
       "8      [polar, codes, gained, extensive, attention, p...\n",
       "9      [propose, use, agent, based, models, abms, ins...\n",
       "10     [structure, time, series, particular, cyclosta...\n",
       "11     [propose, unified, framework, multiperson, pos...\n",
       "12     [well, estimate, probability, classification, ...\n",
       "13     [introduce, novel, observability, continuum, e...\n",
       "14     [giving, provable, guarantees, neural, network...\n",
       "15     [present, skelneton, 2019, challenge, deep, ge...\n",
       "16     [consider, em, mixed, linear, regression, mlr,...\n",
       "17     [work, tackles, fuzzy, joining, strings, natur...\n",
       "18     [multidomain, mdl, aims, obtaining, minimal, a...\n",
       "19     [glioma, constitutes, 80, malignant, primary, ...\n",
       "20     [exchange, involves, source, schema, target, s...\n",
       "21     [speed, accuracy, robots, able, interpret, nat...\n",
       "22     [computer, vision, virtually, every, state, ar...\n",
       "23     [dtw, calculates, similarity, alignment, two, ...\n",
       "24     [plays, important, role, applications, analyti...\n",
       "25     [urban, traffic, optimization, traffic, camera...\n",
       "26     [propose, distributed, offpolicy, actor, criti...\n",
       "27     [distributed, gathering, algorithms, aim, achi...\n",
       "28     [propose, 2d, encoderdecoder, based, deep, arc...\n",
       "29     [propose, approach, obtain, reducedorder, mode...\n",
       "                             ...                        \n",
       "206    [success, convolutional, neural, networks, cnn...\n",
       "207    [rapid, development, digital, information, vol...\n",
       "208    [people, desire, connected, matter, recently, ...\n",
       "209    [study, quantum, classical, transition, bosons...\n",
       "210    [study, sparse, regression, methods, propose, ...\n",
       "211    [much, effort, devoted, last, two, decades, ch...\n",
       "212    [presents, bigearthnet, new, largescale, multi...\n",
       "213    [presents, novel, framework, jointly, exploits...\n",
       "214    [accurate, cell, counting, microscopic, images...\n",
       "215    [study, online, graph, exploration, undirected...\n",
       "216    [recent, research, superresolution, achieved, ...\n",
       "217    [accurately, counting, cells, microscopic, ima...\n",
       "218    [primary, objective, softmax, cross, entropy, ...\n",
       "219    [theory, quantum, cryptography, aims, guarante...\n",
       "220    [appears, insatiable, desire, spawning, new, b...\n",
       "221    [complex, processes, various, events, happen, ...\n",
       "222    [pedestrian, detection, essential, task, auton...\n",
       "223    [given, latency, variability, observed, center...\n",
       "224    [work, formulate, process, generating, explana...\n",
       "225    [alzheimers, disease, ad, common, neurodegener...\n",
       "226    [survey, concerns, sensor, fusion, predictive,...\n",
       "227    [defending, distributed, denial, service, ddos...\n",
       "228    [nanoscale, communications, must, cooperation,...\n",
       "229    [present, explainit, declarative, unsupervised...\n",
       "230    [investigate, problems, class, imbalance, irre...\n",
       "231    [continual, ability, agent, learn, online, non...\n",
       "232    [deep, bayesian, neural, aroused, great, atten...\n",
       "233    [moment, autonomous, cars, probably, biggest, ...\n",
       "234    [investigate, avoidability, unary, patterns, s...\n",
       "235    [aim, discuss, advanced, aspects, image, recon...\n",
       "Name: description, Length: 236, dtype: object"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenize \n",
    "df['description'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
